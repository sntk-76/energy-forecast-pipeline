flowchart TD
  %% STAGE 1: DATA INGESTION
  A1["Raw Data (CSV from OPSD)"] --> A2["DAG #1: Upload to GCS (raw/)"]
  A2 --> A3["GCS: raw/time_series.csv"]

  %% STAGE 2: DATA PROCESSING WITH SPARK
  A3 --> B1["DAG #2: Trigger PySpark Script"]
  B1 --> B2["PySpark (Local)"]
  B2 --> B3["GCS: cleaned/de_energy_data.csv"]

  %% STAGE 3: LOAD TO BIGQUERY
  B3 --> C1["DAG #3: Load Cleaned Data to BigQuery"]
  C1 --> C2["BQ: energy_cleaned.de_hourly_data"]

  %% STAGE 4: DATA MODELING WITH DBT
  C2 --> D1["dbt Models"]
  D1 --> D2["BQ: dbt models"]
  D2 --> D3["dbt Docs/Test Interface"]

  %% STAGE 5: FORECASTING
  D2 --> E1["Jupyter Notebook"]
  E1 --> E2["Prophet/ARIMA Model"]
  E2 --> E3["Export Forecast CSV"]
  E3 --> E4["GCS: forecast/energy_predictions.csv"]

  E4 --> F1["DAG #4: Load Forecast to BigQuery"]
  F1 --> F2["BQ: energy_forecast.predictions"]

  %% STAGE 6: VISUALIZATION
  D2 --> G1["Power BI Dashboard"]
  F2 --> G1

  %% STAGE 7: INFRASTRUCTURE
  subgraph "Cloud Infrastructure (Terraform Managed)"
    I1["GCS Buckets"]
    I2["BigQuery Datasets"]
    I3["Service Accounts"]
    I4["GCP Project Config"]
  end

  A3 --> I1
  B3 --> I1
  C2 --> I2
  F2 --> I2
  D1 --> I2

  %% Airflow Control Plane
  subgraph "Airflow (Dockerized)"
    A2
    B1
    C1
    F1
  end

  %% Local Tools
  subgraph "Local Tools"
    B2
    E1
    G1
  end
